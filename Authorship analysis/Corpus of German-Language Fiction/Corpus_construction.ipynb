{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d8b5208",
   "metadata": {},
   "source": [
    "# Package handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f343b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages required to unpack the compressed corpus file\n",
    "\n",
    "# ! pip install pyunpack\n",
    "# ! pip install patool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32e454",
   "metadata": {},
   "source": [
    "#### External imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import operator as Operator\n",
    "from pyunpack import Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d6afe",
   "metadata": {},
   "source": [
    "#### Internal imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511c0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.os_utils as os_utils\n",
    "import modules.corpus_utils as corpus_utils\n",
    "import modules.posnoise as POSNoise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bc0f1f",
   "metadata": {},
   "source": [
    "# Prepare corpus data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6635e4",
   "metadata": {},
   "source": [
    "#### Define base directory in which all the corpus data/metadata is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f3fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.abspath(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9319734d",
   "metadata": {},
   "source": [
    "#### Create a \"raw corpus\" directory and download original corpus file from the figshare portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e49860",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corpus_directory = Path(base_dir, \"[Raw] Corpus\")\n",
    "raw_corpus_directory.mkdir(exist_ok=True)\n",
    "\n",
    "url = \"https://figshare.com/ndownloader/files/7320866\"\n",
    "raw_corpus_filename = \"Corpus_of_German_Language_Fiction.zip\"\n",
    "\n",
    "dest_filename = Path(raw_corpus_directory, raw_corpus_filename)\n",
    "corpus_utils.download_file(url, dest_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a64cb35",
   "metadata": {},
   "source": [
    "#### Unpack the original corpus file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "Archive(dest_filename).extractall(raw_corpus_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e222a0",
   "metadata": {},
   "source": [
    "#### Move all text files in the sub directory \"corpus-of-german-fiction-txt\" into parent directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_subdir = \"Corpus of German-Language Fiction\"\n",
    "source_dir = Path(raw_corpus_directory, corpus_subdir, \"corpus-of-german-fiction-txt\")\n",
    "text_filepaths = os_utils.list_filepaths(source_dir)\n",
    "\n",
    "for filename in tqdm(text_filepaths):\n",
    "    fname = Path(filename).name\n",
    "    shutil.move(filename, Path(raw_corpus_directory, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3b7157",
   "metadata": {},
   "source": [
    "#### Remove the directory of the extracted zip file with its leftovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfbc69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trash_directory = Path(raw_corpus_directory, corpus_subdir)\n",
    "shutil.rmtree(str(trash_directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf23e9",
   "metadata": {},
   "source": [
    "# Create the authorship attribution (AA) corpus "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84281d0d",
   "metadata": {},
   "source": [
    "#### Create the aa corpus directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67893612",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_corpus_directory = Path(base_dir, \"[AA] Corpus\")\n",
    "aa_corpus_directory.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c6481e",
   "metadata": {},
   "source": [
    "#### Copy all text files from the raw corpus directory to the aa corpus directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3953af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_filepaths = os_utils.list_filepaths(str(raw_corpus_directory))\n",
    "\n",
    "for raw_text_filepath in tqdm(raw_text_filepaths):\n",
    "    fname = Path(raw_text_filepath).name\n",
    "    dest_filepath = Path(aa_corpus_directory, fname)\n",
    "    shutil.copy(raw_text_filepath, dest_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3291423b",
   "metadata": {},
   "source": [
    "#### Create the aa corpus (in-place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c0da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_utils.create_aa_corpus(aa_corpus_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7f048a",
   "metadata": {},
   "source": [
    "#### ...and keep $n$ files per author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a490e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_per_author = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d022ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "os_utils.keep_n_files_in_each_subfolder(aa_corpus_directory, number_of_files_to_keep=texts_per_author)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19742a2",
   "metadata": {},
   "source": [
    "#### Remove authors for which < $n$ documents are available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260b5764",
   "metadata": {},
   "outputs": [],
   "source": [
    "os_utils.delete_subdirs_with_operator_n_files(aa_corpus_directory, texts_per_author, Operator.lt, extension=\".txt\", verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6650c5c",
   "metadata": {},
   "source": [
    "# Pre-process all text files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eac7fd",
   "metadata": {},
   "source": [
    "#### Construct the documents once the pre-processing is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = os_utils.list_filepaths(aa_corpus_directory, include_subdirs=True)    \n",
    "\n",
    "# Restrict the length of each text to max_total_chars (e.g., 7000 characters ~7 kB)\n",
    "corpus_utils.construct_documents(filepaths, max_total_chars=7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a3018c",
   "metadata": {},
   "source": [
    "#### In case the pre-processing led to shorter texts, remove these according to a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a6378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_utils.delete_files_according_to_length(aa_corpus_directory, min_length=1000, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bb3349",
   "metadata": {},
   "source": [
    "#### Ensure there are at maximum 2 documents available for each author. Otherwise, remove affected author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596247f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os_utils.delete_subdirs_with_operator_n_files(aa_corpus_directory, 3, Operator.lt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ec9c41",
   "metadata": {},
   "source": [
    "#### Sort texts per author according to maximum time-span and reduce them to 2 documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc60d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_utils.maximize_time_span_and_remove_inner_documents(aa_corpus_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ceef8f",
   "metadata": {},
   "source": [
    "# Apply POSNoise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382d9c3e",
   "metadata": {},
   "source": [
    "#### POSNoise: An Effective Countermeasure Against Topic Biases in Authorship Analysis <br><br>  https://arxiv.org/abs/2005.06605"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad6f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_filepaths = os_utils.list_filepaths(aa_corpus_directory, include_subdirs=True)\n",
    "\n",
    "for text_filepath in tqdm(text_filepaths):\n",
    "    text = Path(text_filepath).read_text(encoding=\"utf8\")  \n",
    "    posnoised_txt = POSNoise.posnoise(text, model=\"de_core_news_lg\")\n",
    "    Path(text_filepath).write_text(posnoised_txt, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee51474",
   "metadata": {},
   "source": [
    "# Finished"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
